"""
Sales Forecasting Demo - Showcasing all implemented features
Task-7: Complete demonstration of sales forecasting capabilities
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

def load_sample_data():
    """Load the generated sample data"""
    try:
        df = pd.read_csv('data/walmart_sales_data.csv')
        df['Date'] = pd.to_datetime(df['Date'])
        print(f"Loaded dataset with {len(df)} records")
        return df
    except FileNotFoundError:
        print("Dataset not found. Please run src/data_downloader.py first")
        return None

def create_time_features(df):
    """Create time-based features including lag values"""
    print("Creating time-based features...")
    
    df = df.copy()
    df = df.sort_values(['Store', 'Dept', 'Date']).reset_index(drop=True)
    
    # Basic time features
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df['DayOfWeek'] = df['Date'].dt.dayofweek
    df['DayOfYear'] = df['Date'].dt.dayofyear
    df['WeekOfYear'] = df['Date'].dt.isocalendar().week
    df['Quarter'] = df['Date'].dt.quarter
    
    # Cyclical encoding
    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)
    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)
    df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['DayOfWeek'] / 7)
    df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['DayOfWeek'] / 7)
    
    # Lag features (BONUS: Multiple lag periods)
    print("Creating lag features...")
    for lag in [1, 7, 14, 28]:
        df[f'Sales_lag_{lag}'] = df.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(lag)
    
    # Rolling averages (BONUS: Rolling statistics)
    print("Creating rolling averages...")
    for window in [7, 14, 28]:
        df[f'Sales_rolling_mean_{window}'] = df.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(
            lambda x: x.rolling(window=window, min_periods=1).mean()
        )
        df[f'Sales_rolling_std_{window}'] = df.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(
            lambda x: x.rolling(window=window, min_periods=1).std()
        )
    
    return df

def seasonal_analysis(df):
    """Perform seasonal decomposition analysis"""
    print("Performing seasonal analysis...")
    
    # Aggregate data by date for overall seasonal pattern
    daily_sales = df.groupby('Date')['Weekly_Sales'].sum().reset_index()
    
    # Create seasonal plots
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Monthly pattern
    df['Month'] = df['Date'].dt.month
    monthly_avg = df.groupby('Month')['Weekly_Sales'].mean()
    axes[0, 0].plot(monthly_avg.index, monthly_avg.values, marker='o')
    axes[0, 0].set_title('Average Sales by Month')
    axes[0, 0].set_xlabel('Month')
    axes[0, 0].set_ylabel('Average Sales')
    
    # Day of week pattern
    df['DayOfWeek'] = df['Date'].dt.dayofweek
    dow_avg = df.groupby('DayOfWeek')['Weekly_Sales'].mean()
    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
    axes[0, 1].bar(range(7), dow_avg.values)
    axes[0, 1].set_title('Average Sales by Day of Week')
    axes[0, 1].set_xticks(range(7))
    axes[0, 1].set_xticklabels(day_names)
    axes[0, 1].set_ylabel('Average Sales')
    
    # Time series plot
    axes[1, 0].plot(daily_sales['Date'], daily_sales['Weekly_Sales'])
    axes[1, 0].set_title('Total Sales Over Time')
    axes[1, 0].set_xlabel('Date')
    axes[1, 0].set_ylabel('Total Sales')
    axes[1, 0].tick_params(axis='x', rotation=45)
    
    # Holiday vs non-holiday
    holiday_comparison = df.groupby('IsHoliday')['Weekly_Sales'].mean()
    axes[1, 1].bar(['Non-Holiday', 'Holiday'], holiday_comparison.values)
    axes[1, 1].set_title('Holiday vs Non-Holiday Sales')
    axes[1, 1].set_ylabel('Average Sales')
    
    plt.tight_layout()
    plt.savefig('outputs/seasonal_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def train_regression_models(X, y):
    """Train multiple regression models"""
    print("Training regression models...")
    
    # Time-aware split (last 20% for testing)
    split_point = int(len(X) * 0.8)
    X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
    y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]
    
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)
    }
    
    # Add advanced models if available
    try:
        import xgboost as xgb
        models['XGBoost'] = xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0)
    except ImportError:
        print("XGBoost not available")
    
    try:
        import lightgbm as lgb
        models['LightGBM'] = lgb.LGBMRegressor(n_estimators=100, random_state=42, verbosity=-1)
    except ImportError:
        print("LightGBM not available")
    
    results = {}
    
    for name, model in models.items():
        print(f"Training {name}...")
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        # Calculate metrics
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        
        results[name] = {
            'model': model,
            'predictions': y_pred,
            'mae': mae,
            'rmse': rmse,
            'r2': r2
        }
        
        print(f"  MAE: {mae:.2f}")
        print(f"  RMSE: {rmse:.2f}")
        print(f"  RÂ²: {r2:.4f}")
    
    return X_test, y_test, results

def plot_actual_vs_predicted(X_test, y_test, results, dates):
    """Plot actual vs predicted values over time"""
    print("Creating actual vs predicted visualizations...")
    
    n_models = len(results)
    fig, axes = plt.subplots(n_models, 2, figsize=(16, 5*n_models))
    if n_models == 1:
        axes = axes.reshape(1, -1)
    
    for idx, (name, result) in enumerate(results.items()):
        y_pred = result['predictions']
        
        # Time series plot (sample every 50th point for readability)
        sample_idx = slice(None, None, 50)
        axes[idx, 0].plot(dates[sample_idx], y_test.values[sample_idx], 
                         label='Actual', alpha=0.8, linewidth=2, marker='o', markersize=3)
        axes[idx, 0].plot(dates[sample_idx], y_pred[sample_idx], 
                         label='Predicted', alpha=0.8, linewidth=2, marker='s', markersize=3)
        axes[idx, 0].set_title(f'{name} - Actual vs Predicted Over Time')
        axes[idx, 0].set_xlabel('Date')
        axes[idx, 0].set_ylabel('Weekly Sales')
        axes[idx, 0].legend()
        axes[idx, 0].tick_params(axis='x', rotation=45)
        axes[idx, 0].grid(True, alpha=0.3)
        
        # Scatter plot
        axes[idx, 1].scatter(y_test, y_pred, alpha=0.6, s=20)
        # Perfect prediction line
        min_val, max_val = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())
        axes[idx, 1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')
        axes[idx, 1].set_xlabel('Actual Sales')
        axes[idx, 1].set_ylabel('Predicted Sales')
        axes[idx, 1].set_title(f'{name} - Prediction Accuracy (RÂ² = {result["r2"]:.4f})')
        axes[idx, 1].legend()
        axes[idx, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('outputs/actual_vs_predicted.png', dpi=300, bbox_inches='tight')
    plt.show()

def feature_importance_analysis(results, feature_names):
    """Analyze feature importance for tree-based models"""
    tree_models = ['Random Forest', 'XGBoost', 'LightGBM']
    available_models = [name for name in tree_models if name in results]
    
    if not available_models:
        return
    
    fig, axes = plt.subplots(1, len(available_models), figsize=(8*len(available_models), 8))
    if len(available_models) == 1:
        axes = [axes]
    
    for idx, name in enumerate(available_models):
        model = results[name]['model']
        
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
            indices = np.argsort(importances)[::-1][:15]  # Top 15 features
            
            feature_names_subset = [feature_names[i] for i in indices]
            importance_values = importances[indices]
            
            axes[idx].barh(range(len(indices)), importance_values)
            axes[idx].set_yticks(range(len(indices)))
            axes[idx].set_yticklabels(feature_names_subset)
            axes[idx].set_xlabel('Feature Importance')
            axes[idx].set_title(f'{name} - Top 15 Features')
            axes[idx].invert_yaxis()
    
    plt.tight_layout()
    plt.savefig('outputs/feature_importance.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """Main demonstration function"""
    print("=" * 70)
    print("SALES FORECASTING DEMONSTRATION")
    print("Task-7: Walmart Sales Forecasting with Time Series Features")
    print("=" * 70)
    print()
    
    # 1. Load data
    print("ðŸ“Š STEP 1: Loading Walmart Sales Data")
    df = load_sample_data()
    if df is None:
        return
    
    print(f"Dataset shape: {df.shape}")
    print(f"Date range: {df['Date'].min()} to {df['Date'].max()}")
    print(f"Stores: {sorted(df['Store'].unique())}")
    print(f"Departments: {sorted(df['Dept'].unique())}")
    print()
    
    # 2. Create time-based features
    print("ðŸ•’ STEP 2: Creating Time-Based Features")
    df_features = create_time_features(df)
    print(f"Total features created: {df_features.shape[1]}")
    print()
    
    # 3. Seasonal analysis
    print("ðŸ“ˆ STEP 3: Seasonal Decomposition Analysis")
    seasonal_analysis(df_features)
    print()
    
    # 4. Prepare modeling data
    print("ðŸ”§ STEP 4: Preparing Data for Modeling")
    feature_cols = [col for col in df_features.columns if col not in ['Weekly_Sales', 'Date']]
    
    # Handle missing values
    df_clean = df_features[feature_cols + ['Weekly_Sales']].dropna()
    
    if len(df_clean) < len(df_features) * 0.5:
        print("Too many NaN values from lag features. Using basic features only.")
        basic_features = ['Store', 'Dept', 'Year', 'Month', 'Day', 'DayOfWeek', 
                         'Month_sin', 'Month_cos', 'DayOfWeek_sin', 'DayOfWeek_cos',
                         'IsHoliday', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']
        df_clean = df_features[basic_features + ['Weekly_Sales']].dropna()
        feature_cols = basic_features
    
    # Convert boolean columns
    if 'IsHoliday' in df_clean.columns:
        df_clean = df_clean.copy()
        df_clean['IsHoliday'] = df_clean['IsHoliday'].astype(int)
    
    X = df_clean[feature_cols]
    y = df_clean['Weekly_Sales']
    
    print(f"Final dataset: {len(X)} samples, {len(feature_cols)} features")
    print(f"Features: {feature_cols}")
    print()
    
    # 5. Train regression models
    print("ðŸ¤– STEP 5: Training Regression Models")
    X_test, y_test, results = train_regression_models(X, y)
    print()
    
    # 6. Plot results
    print("ðŸ“Š STEP 6: Plotting Actual vs Predicted Values")
    # Get corresponding dates for test set
    split_point = int(len(df_clean) * 0.8)
    test_indices = df_clean.index[split_point:]
    test_dates = df_features.loc[test_indices, 'Date'].values[:len(y_test)]
    
    plot_actual_vs_predicted(X_test, y_test, results, test_dates)
    print()
    
    # 7. Feature importance
    print("ðŸŽ¯ STEP 7: Feature Importance Analysis")
    feature_importance_analysis(results, feature_cols)
    print()
    
    # 8. Summary
    print("=" * 70)
    print("ðŸ“‹ FINAL SUMMARY")
    print("=" * 70)
    
    print("âœ… IMPLEMENTED FEATURES:")
    print("â€¢ Time-based features: day, month, week, quarter, cyclical encoding")
    print("â€¢ Lag values: 1, 7, 14, 28 day lags")
    print("â€¢ Rolling averages: 7, 14, 28 day windows (BONUS)")
    print("â€¢ Seasonal decomposition analysis (BONUS)")
    print("â€¢ Multiple regression models: Linear, Random Forest")
    print("â€¢ Advanced models: XGBoost, LightGBM (BONUS - if available)")
    print("â€¢ Time-aware validation (BONUS)")
    print("â€¢ Actual vs predicted visualization over time")
    print("â€¢ Feature importance analysis")
    print()
    
    print("ðŸ“Š MODEL PERFORMANCE:")
    best_model = max(results.items(), key=lambda x: x[1]['r2'])
    print(f"Best Model: {best_model[0]}")
    print(f"RÂ² Score: {best_model[1]['r2']:.4f}")
    print(f"RMSE: {best_model[1]['rmse']:.2f}")
    print(f"MAE: {best_model[1]['mae']:.2f}")
    print()
    
    print("All models trained successfully!")
    print("Generated visualizations:")
    print("â€¢ seasonal_analysis.png - Seasonal patterns and trends")
    print("â€¢ actual_vs_predicted.png - Model predictions over time")
    print("â€¢ feature_importance.png - Feature importance analysis")
    print()
    print("Task-7 Sales Forecasting: âœ… COMPLETE")

if __name__ == "__main__":
    main()
